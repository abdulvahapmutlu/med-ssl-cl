{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84424a2d-3e68-4f56-8f47-13f5deb3791c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | encoder | VisionTransformer | 5.5 M  | train\n",
      "1 | head    | Linear            | 193    | train\n",
      "2 | crit    | BCEWithLogitsLoss | 0      | train\n",
      "------------------------------------------------------\n",
      "5.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 M     Total params\n",
      "22.098    Total estimated model params size (MB)\n",
      "C:\\Users\\offic\\anaconda3\\envs\\medssl\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "C:\\Users\\offic\\anaconda3\\envs\\medssl\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (17) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75412c3883544ad8f1bba88f44e3593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shenzhen AUC after Task 0: 0.797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params | Mode\n",
      "-----------------------------------------------------\n",
      "0 | encoder | VisionTransformer | 5.5 M  | eval\n",
      "1 | head    | Linear            | 193    | eval\n",
      "2 | crit    | BCEWithLogitsLoss | 0      | eval\n",
      "-----------------------------------------------------\n",
      "5.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 M     Total params\n",
      "22.098    Total estimated model params size (MB)\n",
      "C:\\Users\\offic\\anaconda3\\envs\\medssl\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:298: The number of training batches (10) is smaller than the logging interval Trainer(log_every_n_steps=20). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e50a75a6b7a4227be3b0e50bf5b315f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Shenzhen AUC:   0.852\n",
      "Montgomery AUC:       0.797\n",
      "Backward Transfer Δ:  +0.055\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import random, numpy as np, pandas as pd, torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, Subset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import timm, pytorch_lightning as pl\n",
    "from torchmetrics.classification import BinaryAUROC\n",
    "\n",
    "# ────────────────────────────────────────────────────────────\n",
    "#  Paths  (edit if yours differ)\n",
    "# ────────────────────────────────────────────────────────────\n",
    "CKPT     = Path(r\"C:\\Users\\offic\\medself\\shenzhen_ckpts\\epochepoch=11-aucval_auc=0.896.ckpt\")\n",
    "SHEN_CSV = Path(r\"C:\\Users\\offic\\OneDrive\\Masaüstü\\datasets\\SelfSupervised\\Shenzhen\\shenzhen_metadata.csv\")\n",
    "SHEN_IMG = Path(r\"C:\\Users\\offic\\OneDrive\\Masaüstü\\datasets\\SelfSupervised\\Shenzhen\\images\\images\")\n",
    "MONT_CSV = Path(r\"C:\\Users\\offic\\OneDrive\\Masaüstü\\datasets\\SelfSupervised\\Montgomery\\montgomery_metadata.csv\")\n",
    "MONT_IMG = Path(r\"C:\\Users\\offic\\OneDrive\\Masaüstü\\datasets\\SelfSupervised\\Montgomery\\images\\images\")\n",
    "for p in (CKPT, SHEN_CSV, SHEN_IMG, MONT_CSV, MONT_IMG): assert p.exists(), p\n",
    "\n",
    "# ────────────────────────────────────────────────────────────\n",
    "#  Hyper-params & constants\n",
    "# ────────────────────────────────────────────────────────────\n",
    "DEVICE        = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MEM_SIZE      = 200\n",
    "EWC_LAMBDA    = 0.05\n",
    "SHEN_EPOCHS   = 5\n",
    "MONT_EPOCHS   = 15\n",
    "BATCH_SIZE    = 32\n",
    "\n",
    "# ────────────────────────────────────────────────────────────\n",
    "#  Transforms & Dataset\n",
    "# ────────────────────────────────────────────────────────────\n",
    "def med_tf(train=True, aug=0.5):\n",
    "    ops = [transforms.Resize((224, 224))]\n",
    "    if train:\n",
    "        ops.append(transforms.RandomHorizontalFlip(p=aug))\n",
    "    ops += [transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "    return transforms.Compose(ops)\n",
    "\n",
    "class CXRCSV(Dataset):\n",
    "    def __init__(self, df, img_dir, train=True, aug=0.5):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.dir = img_dir\n",
    "        self.tf  = med_tf(train, aug)\n",
    "        self.targets = [0 if f.lower().strip()==\"normal\" else 1\n",
    "                        for f in self.df[\"findings\"]]\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.tf(Image.open(self.dir / self.df.iloc[idx][\"study_id\"]).convert(\"L\")).repeat(3,1,1)\n",
    "        y = torch.tensor([self.targets[idx]], dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "def make_split(csv_path, img_path, seed=42):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    y  = df[\"findings\"].apply(lambda s: 0 if s.lower().strip()==\"normal\" else 1)\n",
    "    tr, val = train_test_split(np.arange(len(df)), stratify=y,\n",
    "                               test_size=0.2, random_state=seed)\n",
    "    return (CXRCSV(df.iloc[tr],  img_path, True),\n",
    "            CXRCSV(df.iloc[val], img_path, False))\n",
    "\n",
    "shen_train, shen_val = make_split(SHEN_CSV,  SHEN_IMG)\n",
    "mont_train, mont_val = make_split(MONT_CSV,  MONT_IMG)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────\n",
    "#  Continual-learning LightningModule\n",
    "# ────────────────────────────────────────────────────────────\n",
    "class CLModel(pl.LightningModule):\n",
    "    def __init__(self, ckpt_path, lr=1e-4, wd=1e-4):\n",
    "        super().__init__()\n",
    "        # SSL ViT encoder\n",
    "        self.encoder = timm.create_model(\"vit_tiny_patch16_224\",\n",
    "                                         num_classes=0, global_pool=\"token\")\n",
    "        sd = torch.load(ckpt_path, map_location=\"cpu\", weights_only=False)[\"state_dict\"]\n",
    "        self.encoder.load_state_dict({k.replace(\"student.\",\"\"):v for k,v in sd.items()\n",
    "                                      if k.startswith(\"student.\")}, strict=False)\n",
    "        # Detect CLS dim robustly\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 3, 224, 224)\n",
    "            feat  = self.encoder(dummy)\n",
    "            if feat.ndim == 3: feat = feat[:,0]\n",
    "            self.feat_dim = feat.shape[-1]\n",
    "\n",
    "        self.head = nn.Linear(self.feat_dim, 1)\n",
    "        self.lr, self.wd = lr, wd\n",
    "        self.crit = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Replay / EWC storage\n",
    "        self.mem_x, self.mem_y = [], []\n",
    "        self.ewc_mu = None\n",
    "        self.ewc_fisher = None   #  <<< fixed: no unpacking error\n",
    "\n",
    "    # Forward returns (B,1)\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        if z.ndim == 3: z = z[:,0]\n",
    "        return self.head(z)\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        x, y = batch\n",
    "        logits = self(x).squeeze(1)\n",
    "        loss = self.crit(logits, y.squeeze(1))\n",
    "        if self.ewc_mu is not None:\n",
    "            loss += EWC_LAMBDA * sum((f * (p - m).pow(2)).sum()\n",
    "                                     for p, m, f in zip(self.parameters(),\n",
    "                                                        self.ewc_mu,\n",
    "                                                        self.ewc_fisher))\n",
    "        self.log(\"loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=self.wd)\n",
    "\n",
    "    # ---------- Replay helpers ----------\n",
    "    @torch.no_grad()\n",
    "    def add_to_memory(self, dataset):\n",
    "        sel = random.sample(range(len(dataset)),\n",
    "                            k=min(MEM_SIZE, len(dataset)))\n",
    "        for xs, ys in DataLoader(Subset(dataset, sel), batch_size=64):\n",
    "            # store individual samples   <<< fixed\n",
    "            for xi, yi in zip(xs, ys):\n",
    "                self.mem_x.append(xi.cpu())\n",
    "                self.mem_y.append(yi.cpu())\n",
    "        self.mem_x, self.mem_y = self.mem_x[-MEM_SIZE:], self.mem_y[-MEM_SIZE:]\n",
    "\n",
    "    # ---------- Fisher computation ----------\n",
    "    def compute_fisher(self, dataset, samples=600):\n",
    "        fisher = {n: torch.zeros_like(p) for n, p in self.named_parameters()}\n",
    "        loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "        cnt = 0\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            loss = self.crit(self(x).squeeze(1), y.squeeze(1))\n",
    "            self.zero_grad(); loss.backward()\n",
    "            for (n, p) in self.named_parameters():\n",
    "                fisher[n] += p.grad.detach() ** 2\n",
    "            cnt += 1\n",
    "            if cnt * 32 >= samples: break\n",
    "        for n in fisher: fisher[n] /= cnt\n",
    "        self.ewc_mu     = [p.detach().clone() for p in self.parameters()]\n",
    "        self.ewc_fisher = [fisher[n] for n, _ in self.named_parameters()]\n",
    "\n",
    "# ────────────────────────────────────────────────────────────\n",
    "#  Evaluation helper\n",
    "# ────────────────────────────────────────────────────────────\n",
    "def auc_on(model, dataset):\n",
    "    model.to(DEVICE).eval()\n",
    "    auc = BinaryAUROC().to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        for x, y in DataLoader(dataset, batch_size=64):\n",
    "            auc.update(torch.sigmoid(model(x.to(DEVICE)).squeeze(1)),\n",
    "                       y.to(DEVICE).int().squeeze(1))\n",
    "    return auc.compute().item()\n",
    "\n",
    "# ────────────────────────────────────────────────────────────\n",
    "#  Phase 0 – Train on Shenzhen\n",
    "# ────────────────────────────────────────────────────────────\n",
    "pl.seed_everything(42)\n",
    "model = CLModel(CKPT).to(DEVICE)\n",
    "\n",
    "pl.Trainer(max_epochs=SHEN_EPOCHS, accelerator=DEVICE,\n",
    "           devices=1, log_every_n_steps=20).fit(\n",
    "    model, DataLoader(shen_train, BATCH_SIZE, shuffle=True, num_workers=0))\n",
    "\n",
    "shen_auc_before = auc_on(model, shen_val)\n",
    "print(f\"\\nShenzhen AUC after Task 0: {shen_auc_before:.3f}\")\n",
    "\n",
    "model.add_to_memory(shen_train)\n",
    "model.compute_fisher(shen_train)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────\n",
    "#  Phase 1 – Train on Montgomery + replay\n",
    "# ────────────────────────────────────────────────────────────\n",
    "class ReplayDS(Dataset):\n",
    "    def __init__(self, xs, ys): self.xs, self.ys = xs, ys\n",
    "    def __len__(self): return len(self.xs)\n",
    "    def __getitem__(self, i):  return self.xs[i], self.ys[i]\n",
    "\n",
    "combo_train = ConcatDataset([mont_train,\n",
    "                             ReplayDS(model.mem_x, model.mem_y)])\n",
    "\n",
    "pl.Trainer(max_epochs=MONT_EPOCHS, accelerator=DEVICE,\n",
    "           devices=1, log_every_n_steps=20).fit(\n",
    "    model, DataLoader(combo_train, BATCH_SIZE, shuffle=True, num_workers=0))\n",
    "\n",
    "# ────────────────────────────────────────────────────────────\n",
    "#  Final metrics\n",
    "# ────────────────────────────────────────────────────────────\n",
    "shen_auc_after = auc_on(model, shen_val)\n",
    "mont_auc       = auc_on(model, mont_val)\n",
    "\n",
    "print(f\"\\nFinal Shenzhen AUC:   {shen_auc_after:.3f}\")\n",
    "print(f\"Montgomery AUC:       {mont_auc:.3f}\")\n",
    "print(f\"Backward Transfer Δ:  {shen_auc_after - shen_auc_before:+.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65eee51-1fe0-4dd5-8565-76c633174d10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
