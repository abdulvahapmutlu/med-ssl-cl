{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "206d992c-6aed-4068-842c-3002c591091b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params | Mode  | In sizes         | Out sizes\n",
      "-------------------------------------------------------------------------------------\n",
      "0 | encoder | VisionTransformer | 5.5 M  | train | [1, 3, 224, 224] | [1, 192] \n",
      "1 | head    | Linear            | 193    | train | [1, 192]         | [1, 1]   \n",
      "2 | loss_fn | BCEWithLogitsLoss | 0      | train | ?                | ?        \n",
      "-------------------------------------------------------------------------------------\n",
      "5.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 M     Total params\n",
      "22.098    Total estimated model params size (MB)\n",
      "C:\\Users\\offic\\anaconda3\\envs\\medssl\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c9ca27796e4b0f89a257d1f732b3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shenzhen AUC after Task 0: 0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params | Mode  | In sizes         | Out sizes\n",
      "-------------------------------------------------------------------------------------\n",
      "0 | encoder | VisionTransformer | 5.5 M  | eval  | [1, 3, 224, 224] | [1, 192] \n",
      "1 | head    | Linear            | 193    | eval  | [1, 192]         | [1, 1]   \n",
      "2 | loss_fn | BCEWithLogitsLoss | 0      | train | ?                | ?        \n",
      "-------------------------------------------------------------------------------------\n",
      "5.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 M     Total params\n",
      "22.098    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d212458678c4ded9c23e828ff760dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Montgomery AUC: 0.724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params | Mode  | In sizes         | Out sizes\n",
      "-------------------------------------------------------------------------------------\n",
      "0 | encoder | VisionTransformer | 5.5 M  | eval  | [1, 3, 224, 224] | [1, 192] \n",
      "1 | head    | Linear            | 193    | eval  | [1, 192]         | [1, 1]   \n",
      "2 | loss_fn | BCEWithLogitsLoss | 0      | train | ?                | ?        \n",
      "-------------------------------------------------------------------------------------\n",
      "1.3 M     Trainable params\n",
      "4.2 M     Non-trainable params\n",
      "5.5 M     Total params\n",
      "22.098    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a43beb9c21f4be1ae2a85faea38ecd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=12` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type              | Params | Mode  | In sizes         | Out sizes\n",
      "-------------------------------------------------------------------------------------\n",
      "0 | encoder | VisionTransformer | 5.5 M  | eval  | [1, 3, 224, 224] | [1, 192] \n",
      "1 | head    | Linear            | 193    | eval  | [1, 192]         | [1, 1]   \n",
      "2 | loss_fn | BCEWithLogitsLoss | 0      | train | ?                | ?        \n",
      "-------------------------------------------------------------------------------------\n",
      "2.7 M     Trainable params\n",
      "2.9 M     Non-trainable params\n",
      "5.5 M     Total params\n",
      "22.098    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc8ddbdee2344aa854dde5e501a46d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "──────── Final AUCs ────────\n",
      "Shenzhen:   0.760\n",
      "Montgomery: 0.724\n",
      "MIAS:       0.696\n",
      "Backward Transfer Δ (Shenzhen): +0.002\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================\n",
    "#  ♦♦  Continual SSL→CL pipeline – v8.1\n",
    "#      (bug-fixed: replay helpers restored)\n",
    "# ===========================================================\n",
    "from pathlib import Path\n",
    "import random, numpy as np, pandas as pd, torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import timm, pytorch_lightning as pl\n",
    "from torchmetrics.classification import BinaryAUROC\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "# ───────────────────────── paths ────────────────────────────\n",
    "CKPT     = Path(r\"C:\\Users\\offic\\medself\\shenzhen_ckpts\\epochepoch=11-aucval_auc=0.896.ckpt\")\n",
    "SHEN_CSV = Path(r\"C:\\Users\\offic\\OneDrive\\Masaüstü\\datasets\\SelfSupervised\\Shenzhen\\shenzhen_metadata.csv\")\n",
    "SHEN_IMG = Path(r\"C:\\Users\\offic\\OneDrive\\Masaüstü\\datasets\\SelfSupervised\\Shenzhen\\images\\images\")\n",
    "MONT_CSV = Path(r\"C:\\Users\\offic\\OneDrive\\Masaüstü\\datasets\\SelfSupervised\\Montgomery\\montgomery_metadata.csv\")\n",
    "MONT_IMG = Path(r\"C:\\Users\\offic\\OneDrive\\Masaüstü\\datasets\\SelfSupervised\\Montgomery\\images\\images\")\n",
    "MIAS_CSV = Path(r\"C:\\Users\\offic\\OneDrive\\Masaüstü\\datasets\\SelfSupervised\\MIAS\\mias_info.csv\")\n",
    "MIAS_IMG = Path(r\"C:\\Users\\offic\\OneDrive\\Masaüstü\\datasets\\SelfSupervised\\MIAS\\images\")\n",
    "for p in (CKPT, SHEN_CSV, SHEN_IMG, MONT_CSV, MONT_IMG, MIAS_CSV, MIAS_IMG):\n",
    "    assert p.exists(), p\n",
    "\n",
    "# ────────────────────── hyper-params ───────────────────────\n",
    "DEVICE   = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH    = 32\n",
    "GRAD_ACC = 2                  # → effective batch = 64\n",
    "MEM_SIZE = 200\n",
    "EWC_LMB  = 0.05\n",
    "EPOCHS   = dict(shen=5, mont=25, mias=[12, 25])\n",
    "LRS      = dict(shen=1e-4, mont=3e-4, mias_head=3e-4, mias_mid=1e-4)\n",
    "\n",
    "# ───────────────────── transforms / datasets ───────────────\n",
    "def med_tf(train=True):\n",
    "    if train:\n",
    "        ops = [\n",
    "            transforms.Resize(256),\n",
    "            transforms.RandomResizedCrop(224, scale=(0.85, 1.0), ratio=(0.9, 1.1)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(5),\n",
    "        ]\n",
    "    else:\n",
    "        ops = [transforms.Resize(256), transforms.CenterCrop(224)]\n",
    "    ops += [transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "    return transforms.Compose(ops)\n",
    "\n",
    "class CXRCSV(Dataset):\n",
    "    def __init__(self, df, img_dir, train=True):\n",
    "        self.df, self.dir = df.reset_index(drop=True), img_dir\n",
    "        self.tf   = med_tf(train)\n",
    "        self.tgts = [0 if f.lower().strip() == \"normal\" else 1\n",
    "                     for f in self.df[\"findings\"]]\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.dir / self.df.iloc[idx][\"study_id\"]\n",
    "        x   = self.tf(Image.open(img).convert(\"L\")).repeat(3, 1, 1)\n",
    "        y   = torch.tensor([self.tgts[idx]], dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "def split_cxr(csv, img):\n",
    "    df = pd.read_csv(csv)\n",
    "    y  = df[\"findings\"].apply(lambda s: 0 if s.lower().strip() == \"normal\" else 1)\n",
    "    tr, val = train_test_split(np.arange(len(df)), test_size=0.2,\n",
    "                               stratify=y, random_state=42)\n",
    "    return CXRCSV(df.iloc[tr], img, True), CXRCSV(df.iloc[val], img, False)\n",
    "\n",
    "shen_train, shen_val = split_cxr(SHEN_CSV, SHEN_IMG)\n",
    "mont_train, mont_val = split_cxr(MONT_CSV, MONT_IMG)\n",
    "\n",
    "class MIASCSV(Dataset):\n",
    "    def __init__(self, df, img_dir, train=True):\n",
    "        self.df, self.dir = df.reset_index(drop=True), img_dir\n",
    "        self.tf = med_tf(train)\n",
    "        sev = self.df[\"SEVERITY\"].fillna(\"B\").astype(str).str.upper()\n",
    "        self.tgts = [1 if s.startswith(\"M\") else 0 for s in sev]\n",
    "        self.pos  = [i for i, t in enumerate(self.tgts) if t == 1]\n",
    "        self.neg  = [i for i, t in enumerate(self.tgts) if t == 0]\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        stem = self.df.iloc[idx][\"REFNUM\"]\n",
    "        f = next(self.dir / f\"{stem}{e}\"\n",
    "                 for e in (\".png\", \".pgm\") if (self.dir / f\"{stem}{e}\").exists())\n",
    "        x = self.tf(Image.open(f).convert(\"L\")).repeat(3, 1, 1)\n",
    "        y = torch.tensor([self.tgts[idx]], dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "def split_mias():\n",
    "    df = pd.read_csv(MIAS_CSV)\n",
    "    sev = df[\"SEVERITY\"].fillna(\"B\").astype(str).str.upper()\n",
    "    y   = sev.map(lambda s: 1 if s.startswith(\"M\") else 0)\n",
    "    tr, val = train_test_split(np.arange(len(df)), test_size=0.2,\n",
    "                               stratify=y, random_state=42)\n",
    "    return MIASCSV(df.iloc[tr], MIAS_IMG, True), MIASCSV(df.iloc[val], MIAS_IMG, False)\n",
    "\n",
    "mias_train, mias_val = split_mias()\n",
    "\n",
    "# ───────── balanced & malignant-oversample dataset ─────────\n",
    "class BalancedDataset(Dataset):\n",
    "    def __init__(self, cur_ds, rep_x, rep_y, oversample=False):\n",
    "        self.cur, self.rep, self.repy = cur_ds, rep_x, rep_y\n",
    "        self.oversample = oversample and hasattr(cur_ds, \"pos\")\n",
    "        self.pos = cur_ds.pos if self.oversample else None\n",
    "        self.neg = cur_ds.neg if self.oversample else None\n",
    "        self.n   = max(len(self.cur), len(self.rep)) * 2 if self.rep else len(self.cur)\n",
    "    def __len__(self): return self.n\n",
    "    def __getitem__(self, idx):\n",
    "        if self.rep and idx % 2 == 1:        # replay slot\n",
    "            r = (idx // 2) % len(self.rep)\n",
    "            return self.rep[r], self.repy[r]\n",
    "        if self.oversample:\n",
    "            idx_cur = random.choice(self.pos) if random.random() < 0.67 else random.choice(self.neg)\n",
    "        else:\n",
    "            idx_cur = (idx // 2) % len(self.cur)\n",
    "        return self.cur[idx_cur]\n",
    "\n",
    "# ───────────── lightning continual model ───────────────────\n",
    "class CLModel(pl.LightningModule):\n",
    "    def __init__(self, ckpt_path, init_lr, wd=1e-4):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=[\"ckpt_path\"])\n",
    "\n",
    "        # backbone\n",
    "        self.encoder = timm.create_model(\n",
    "            \"vit_tiny_patch16_224\", num_classes=0, global_pool=\"token\"\n",
    "        )\n",
    "        ckpt = torch.load(ckpt_path, map_location=\"cpu\", weights_only=False)[\"state_dict\"]\n",
    "        self.encoder.load_state_dict(\n",
    "            {k.replace(\"student.\", \"\"): v for k, v in ckpt.items() if k.startswith(\"student.\")},\n",
    "            strict=False,\n",
    "        )\n",
    "\n",
    "        # head\n",
    "        with torch.no_grad():\n",
    "            z = self.encoder(torch.zeros(1, 3, 224, 224))\n",
    "            z = z[:, 0] if z.ndim == 3 else z\n",
    "        self.head = nn.Linear(z.shape[-1], 1)\n",
    "\n",
    "        # misc\n",
    "        self.base_lr = init_lr\n",
    "        self.wd      = wd\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()              # overridden per task\n",
    "        self.example_input_array = torch.zeros(1, 3, 224, 224)\n",
    "\n",
    "        # continual-learning state\n",
    "        self.mem_x, self.mem_y = [], []                    # replay buffer\n",
    "        self.ewc_mu, self.ewc_f = None, None\n",
    "\n",
    "    # ─────────── utilities ─────────────────────────────────\n",
    "    def set_pos_weight(self, ds):\n",
    "        \"\"\"Set task-specific BCE pos_weight from dataset.\"\"\"\n",
    "        d = ds.cur if isinstance(ds, BalancedDataset) else ds\n",
    "        pos = sum(d.tgts)\n",
    "        neg = len(d) - pos\n",
    "        pw  = torch.tensor([neg / pos]) if pos > 0 else torch.tensor([1.0])\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss(pos_weight=pw.to(self.device))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def add_to_memory(self, dataset):\n",
    "        sel = random.sample(range(len(dataset)), k=min(MEM_SIZE, len(dataset)))\n",
    "        for xs, ys in DataLoader(Subset(dataset, sel), batch_size=64, num_workers=0):\n",
    "            for xi, yi in zip(xs, ys):\n",
    "                self.mem_x.append(xi.cpu())\n",
    "                self.mem_y.append(yi.cpu())\n",
    "        self.mem_x, self.mem_y = self.mem_x[-MEM_SIZE:], self.mem_y[-MEM_SIZE:]\n",
    "\n",
    "    def compute_fisher(self, dataset, samples=600):\n",
    "        fisher = {n: torch.zeros_like(p) for n, p in self.named_parameters()}\n",
    "        loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "        cnt = 0\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "            loss = self.loss_fn(self(x).squeeze(1), y.squeeze(1))\n",
    "            self.zero_grad(); loss.backward()\n",
    "            for n, p in self.named_parameters():\n",
    "                fisher[n] += p.grad.detach() ** 2\n",
    "            cnt += 1\n",
    "            if cnt * 32 >= samples:\n",
    "                break\n",
    "        for n in fisher:\n",
    "            fisher[n] /= cnt\n",
    "        self.ewc_mu = [p.detach().clone() for p in self.parameters()]\n",
    "        self.ewc_f  = [fisher[n] for n, _ in self.named_parameters()]\n",
    "\n",
    "    # ─────────── forward / training / optim ────────────────\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        z = z[:, 0] if z.ndim == 3 else z\n",
    "        return self.head(z)\n",
    "\n",
    "    def _total_loss(self, logits, y):\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        if self.ewc_mu is not None:\n",
    "            loss += EWC_LMB * sum(\n",
    "                (f * (p - m).pow(2)).sum()\n",
    "                for p, m, f in zip(self.parameters(), self.ewc_mu, self.ewc_f)\n",
    "            )\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        x, y  = batch\n",
    "        loss  = self._total_loss(self(x).squeeze(1), y.squeeze(1))\n",
    "        self.log(\"loss\", loss, prog_bar=True)\n",
    "        return loss                                # Lightning handles grad-acc\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt   = torch.optim.AdamW(self.parameters(), lr=self.base_lr, weight_decay=self.wd)\n",
    "        sched = CosineAnnealingLR(opt, T_max=20)   # will be patched per phase\n",
    "        return [opt], [sched]\n",
    "\n",
    "# ──────────── metrics helper ───────────────────────────────\n",
    "def auc_on(model, ds):\n",
    "    model.eval().to(DEVICE)\n",
    "    auc = BinaryAUROC().to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        for x, y in DataLoader(ds, batch_size=64, num_workers=0):\n",
    "            preds = torch.sigmoid(model(x.to(DEVICE)).squeeze(1))\n",
    "            auc.update(preds, y.to(DEVICE).int().squeeze(1))\n",
    "    return auc.compute().item()\n",
    "\n",
    "# ───────── helper to run one phase with its own opt/sched ──\n",
    "def run_phase(model, train_ds, epochs, lr, t_max):\n",
    "    model.set_pos_weight(train_ds)\n",
    "\n",
    "    def _cfg(self):\n",
    "        opt   = torch.optim.AdamW(self.parameters(), lr=lr, weight_decay=self.wd)\n",
    "        sched = CosineAnnealingLR(opt, T_max=t_max)\n",
    "        return [opt], [sched]\n",
    "\n",
    "    original = model.configure_optimizers\n",
    "    model.configure_optimizers = _cfg.__get__(model, model.__class__)\n",
    "\n",
    "    pl.Trainer(\n",
    "        max_epochs           = epochs,\n",
    "        accelerator          = DEVICE,\n",
    "        devices              = 1,\n",
    "        log_every_n_steps    = 10,\n",
    "        gradient_clip_val    = 1.0,\n",
    "        accumulate_grad_batches = GRAD_ACC,\n",
    "    ).fit(model, DataLoader(train_ds, BATCH, shuffle=True, num_workers=0))\n",
    "\n",
    "    model.configure_optimizers = original  # restore\n",
    "\n",
    "# ─────────────────── training pipeline ─────────────────────\n",
    "pl.seed_everything(42)\n",
    "model = CLModel(CKPT, init_lr=LRS[\"shen\"]).to(DEVICE)\n",
    "\n",
    "# Task 0 – Shenzhen ----------------------------------------\n",
    "run_phase(model, shen_train, EPOCHS[\"shen\"],\n",
    "          lr=LRS[\"shen\"], t_max=EPOCHS[\"shen\"] * 2)\n",
    "shen_auc0 = auc_on(model, shen_val)\n",
    "print(f\"\\nShenzhen AUC after Task 0: {shen_auc0:.3f}\")\n",
    "\n",
    "model.add_to_memory(shen_train); model.compute_fisher(shen_train)\n",
    "\n",
    "# Task 1 – Montgomery --------------------------------------\n",
    "model.base_lr = LRS[\"mont\"]\n",
    "train1 = BalancedDataset(mont_train, model.mem_x, model.mem_y)\n",
    "run_phase(model, train1, EPOCHS[\"mont\"],\n",
    "          lr=LRS[\"mont\"], t_max=EPOCHS[\"mont\"] * 2)\n",
    "mont_auc = auc_on(model, mont_val)\n",
    "print(f\"Montgomery AUC: {mont_auc:.3f}\")\n",
    "\n",
    "model.add_to_memory(mont_train); model.compute_fisher(mont_train)\n",
    "\n",
    "# Task 2 – MIAS (Phase-1 & Phase-2) -------------------------\n",
    "# freeze all encoder blocks first\n",
    "for p in model.encoder.parameters(): p.requires_grad = False\n",
    "for p in model.head.parameters(): p.requires_grad = True\n",
    "\n",
    "# Phase-1: unfreeze last 3 blocks\n",
    "for blk in model.encoder.blocks[9:]:\n",
    "    for p in blk.parameters(): p.requires_grad = True\n",
    "train2a = BalancedDataset(mias_train, model.mem_x, model.mem_y, oversample=True)\n",
    "run_phase(model, train2a, EPOCHS[\"mias\"][0],\n",
    "          lr=LRS[\"mias_head\"], t_max=EPOCHS[\"mias\"][0] * 2)\n",
    "\n",
    "# Phase-2: unfreeze blocks 6-8 as well\n",
    "for blk in model.encoder.blocks[6:9]:\n",
    "    for p in blk.parameters(): p.requires_grad = True\n",
    "train2b = BalancedDataset(mias_train, model.mem_x, model.mem_y, oversample=True)\n",
    "run_phase(model, train2b, EPOCHS[\"mias\"][1],\n",
    "          lr=LRS[\"mias_mid\"], t_max=EPOCHS[\"mias\"][1] * 2)\n",
    "\n",
    "# ─────────────── final metrics ─────────────────────────────\n",
    "shen_auc_f = auc_on(model, shen_val)\n",
    "mont_auc_f = auc_on(model, mont_val)\n",
    "mias_auc_f = auc_on(model, mias_val)\n",
    "\n",
    "print(\"\\n──────── Final AUCs ────────\")\n",
    "print(f\"Shenzhen:   {shen_auc_f:.3f}\")\n",
    "print(f\"Montgomery: {mont_auc_f:.3f}\")\n",
    "print(f\"MIAS:       {mias_auc_f:.3f}\")\n",
    "print(f\"Backward Transfer Δ (Shenzhen): {shen_auc_f - shen_auc0:+.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
