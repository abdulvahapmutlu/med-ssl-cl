{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "505446e5-83cd-4de5-ba4e-860972411274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\offic\\anaconda3\\envs\\medssl\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, RichProgressBar\n",
    "import timm, torchmetrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "from optuna.integration.pytorch_lightning import PyTorchLightningPruningCallback\n",
    "\n",
    "# 🔒 paths — adjust only if your files live elsewhere\n",
    "CKPT_PATH = Path(r\"C:\\Users\\offic\\medself\\checkpoints\\epoch=39-step=12280.ckpt\")\n",
    "CSV_PATH  = Path(r\"C:\\Users\\offic\\OneDrive\\Masaüstü\\datasets\\SelfSupervised\\Shenzhen\\shenzhen_metadata.csv\")\n",
    "IMG_DIR   = Path(r\"C:\\Users\\offic\\OneDrive\\Masaüstü\\datasets\\SelfSupervised\\Shenzhen\\images\\images\")\n",
    "\n",
    "assert CKPT_PATH.exists(), \"Checkpoint not found\"\n",
    "assert CSV_PATH.exists(),  \"CSV not found\"\n",
    "assert IMG_DIR.exists(),   \"Image folder not found\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c55491ab-8469-4b6b-813e-abf43da36ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityTransform:\n",
    "    def __call__(self, x):\n",
    "        return x\n",
    "\n",
    "def med_transform(img_size=224, train=True):\n",
    "    mean = std = [0.5]\n",
    "    ops = [transforms.Resize((img_size, img_size))]\n",
    "    if train:\n",
    "        ops.append(transforms.RandomHorizontalFlip())\n",
    "    ops += [transforms.ToTensor(), transforms.Normalize(mean, std)]\n",
    "    return transforms.Compose(ops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c915cb87-1911-4391-81cd-d8efa9b547ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShenzhenCSV(Dataset):\n",
    "    \"\"\"Load grayscale PNG + binary label from metadata CSV.\"\"\"\n",
    "    def __init__(self, df: pd.DataFrame, img_dir: Path, train=True):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.tf = med_transform(train=train)\n",
    "\n",
    "    @staticmethod\n",
    "    def _label(findings: str) -> int:\n",
    "        return 0 if findings.lower().strip() == \"normal\" else 1\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(self.img_dir / row[\"study_id\"]).convert(\"L\")\n",
    "        x = self.tf(img).repeat(3, 1, 1)      # (3,224,224)\n",
    "        y = torch.tensor(self._label(row[\"findings\"]), dtype=torch.float32)\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e662f57-e85e-489b-969d-9c48f4b81870",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShenzhenDM(pl.LightningDataModule):\n",
    "    def __init__(self, csv_path: Path, img_dir: Path,\n",
    "                 batch=32, workers=0, seed=42):\n",
    "        super().__init__()\n",
    "        self.csv_path, self.img_dir = csv_path, img_dir\n",
    "        self.batch, self.workers, self.seed = batch, workers, seed\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        df = pd.read_csv(self.csv_path)\n",
    "        labels = df[\"findings\"].apply(lambda s: 0 if s.lower().strip()==\"normal\" else 1)\n",
    "        train_idx, temp_idx = train_test_split(\n",
    "            np.arange(len(df)), test_size=0.25,\n",
    "            stratify=labels, random_state=self.seed\n",
    "        )\n",
    "        val_idx, test_idx = train_test_split(\n",
    "            temp_idx, test_size=0.40,\n",
    "            stratify=labels.iloc[temp_idx], random_state=self.seed\n",
    "        )\n",
    "        self.train_ds = ShenzhenCSV(df.iloc[train_idx], self.img_dir, train=True)\n",
    "        self.val_ds   = ShenzhenCSV(df.iloc[val_idx],   self.img_dir, train=False)\n",
    "        self.test_ds  = ShenzhenCSV(df.iloc[test_idx],  self.img_dir, train=False)\n",
    "\n",
    "    def _dl(self, ds, shuffle=False):\n",
    "        return DataLoader(ds, self.batch, shuffle=shuffle,\n",
    "                          num_workers=self.workers, pin_memory=True)\n",
    "\n",
    "    def train_dataloader(self): return self._dl(self.train_ds, True)\n",
    "    def val_dataloader(self):   return self._dl(self.val_ds)\n",
    "    def test_dataloader(self):  return self._dl(self.test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a72ea17a-5383-4005-a26b-a954ba8e9cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitTBFinetune(pl.LightningModule):\n",
    "    def __init__(self, ckpt_path: Path, freeze_epochs=3, lr=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # ── 1. Build ViT-Tiny encoder and load SSL weights ───────────\n",
    "        self.encoder = timm.create_model(\n",
    "            \"vit_tiny_patch16_224\", num_classes=0, global_pool=\"token\"\n",
    "        )\n",
    "        ckpt = torch.load(ckpt_path, map_location=\"cpu\")[\"state_dict\"]\n",
    "        self.encoder.load_state_dict(\n",
    "            {k.replace(\"student.\", \"\"): v for k, v in ckpt.items()\n",
    "             if k.startswith(\"student.\")},\n",
    "            strict=False,\n",
    "        )\n",
    "\n",
    "        # ── 2. Auto-detect output feature length ─────────────────────\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 3, 224, 224)\n",
    "            feat = self.encoder(dummy)\n",
    "            if feat.ndim == 3:       # (B, tokens, dim) → CLS token\n",
    "                feat = feat[:, 0]\n",
    "            self.feat_dim = feat.shape[-1]\n",
    "\n",
    "        # ── 3. Classification head that matches discovered dim ───────\n",
    "        self.head = nn.Linear(self.feat_dim, 1)\n",
    "\n",
    "        # ── other hyper-params & metrics ─────────────────────────────\n",
    "        self.freeze_epochs, self.lr = freeze_epochs, lr\n",
    "        self.auc = torchmetrics.AUROC(task=\"binary\")\n",
    "\n",
    "    # Forward returns logits\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        if z.ndim == 3:          # CLS token\n",
    "            z = z[:, 0]\n",
    "        return self.head(z).squeeze(1)\n",
    "\n",
    "    def training_step(self, batch, _):\n",
    "        x, y = batch\n",
    "        loss = F.binary_cross_entropy_with_logits(self(x), y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, _):\n",
    "        x, y = batch\n",
    "        preds = torch.sigmoid(self(x))\n",
    "        self.auc.update(preds, y.int())\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        val_auc = self.auc.compute(); self.auc.reset()\n",
    "        self.log(\"val_auc\", val_auc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        freeze = self.current_epoch < self.freeze_epochs\n",
    "        for p in self.encoder.parameters():\n",
    "            p.requires_grad = not freeze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2df05f72-91f7-4444-b3d5-c652db0b86d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_shen = ShenzhenDM(CSV_PATH, IMG_DIR, batch=32, workers=0)\n",
    "model_tb = LitTBFinetune(CKPT_PATH, freeze_epochs=3, lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0023412-db0b-49de-9674-e649b356eebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(dirpath=\"shenzhen_ckpts\",\n",
    "                    filename=\"epoch{epoch}-auc{val_auc:.3f}\",\n",
    "                    monitor=\"val_auc\", mode=\"max\", save_top_k=1),\n",
    "    EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=4),\n",
    "    RichProgressBar(),\n",
    "]\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=1,\n",
    "    max_epochs=15,\n",
    "    precision=\"bf16-mixed\" if torch.cuda.is_available() else 32,\n",
    "    callbacks=callbacks,\n",
    "    log_every_n_steps=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f85842f-2d7a-44fa-a7ed-212b49f80c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\offic\\anaconda3\\envs\\medssl\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:652: Checkpoint directory C:\\Users\\offic\\medself\\shenzhen_ckpts exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name    </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ encoder │ VisionTransformer │  5.5 M │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ head    │ Linear            │    193 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ auc     │ BinaryAUROC       │      0 │ train │\n",
       "└───┴─────────┴───────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName   \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ encoder │ VisionTransformer │  5.5 M │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ head    │ Linear            │    193 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ auc     │ BinaryAUROC       │      0 │ train │\n",
       "└───┴─────────┴───────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 5.5 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 5.5 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 22                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 5.5 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 5.5 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 22                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a64892f892d4dd1b1130d31cbd33913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">C:\\Users\\offic\\anaconda3\\envs\\medssl\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: \n",
       "The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n",
       "`num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "C:\\Users\\offic\\anaconda3\\envs\\medssl\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: \n",
       "The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n",
       "`num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">C:\\Users\\offic\\anaconda3\\envs\\medssl\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: \n",
       "The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n",
       "`num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "C:\\Users\\offic\\anaconda3\\envs\\medssl\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:424: \n",
       "The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the \n",
       "`num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model_tb, dm_shen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e9d35d-597b-4b1d-8c96-76644cb47762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
