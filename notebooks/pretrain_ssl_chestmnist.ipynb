{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "738b9d0f-b1fc-426e-9280-3c5573975534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 39/39 <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">614/614</span> <span style=\"color: #8a8a8a; text-decoration-color: #8a8a8a\">1:37:57 • 0:00:00</span> <span style=\"color: #b2b2b2; text-decoration-color: #b2b2b2\">0.14it/s</span> <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">v_num: 7.000 train_loss: 0.002</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Epoch 39/39 \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[37m614/614\u001b[0m \u001b[38;5;245m1:37:57 • 0:00:00\u001b[0m \u001b[38;5;249m0.14it/s\u001b[0m \u001b[37mv_num: 7.000 train_loss: 0.002\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=40` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import (\n",
    "    ModelCheckpoint,\n",
    "    LearningRateMonitor,\n",
    "    RichProgressBar,\n",
    ")\n",
    "from pytorch_lightning.callbacks.progress.rich_progress import RichProgressBarTheme\n",
    "\n",
    "import timm\n",
    "\n",
    "# ─────────── 1) Transforms & Dataset ───────────\n",
    "\n",
    "def med_transform(img_size=224, gray=True):\n",
    "    mean, std = ([0.5], [0.5]) if gray else ([0.485,0.456,0.406], [0.229,0.224,0.225])\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size), antialias=True),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std),\n",
    "    ])\n",
    "\n",
    "class ChestNpz(Dataset):\n",
    "    def __init__(self, npz_path: Path, split: str):\n",
    "        arr = np.load(npz_path)\n",
    "        if split == \"test\":\n",
    "            self.x, self.y = arr[\"test_images\"], arr[\"test_labels\"]\n",
    "        else:\n",
    "            x, y = arr[\"train_images\"], arr[\"train_labels\"]\n",
    "            n_val = int(0.10 * len(x))\n",
    "            if split == \"train\":\n",
    "                self.x, self.y = x[:-n_val], y[:-n_val]\n",
    "            else:\n",
    "                self.x, self.y = x[-n_val:], y[-n_val:]\n",
    "        self.tf = med_transform(gray=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = (self.x[idx] * 255).astype(\"uint8\")\n",
    "        img = Image.fromarray(img).convert(\"L\")\n",
    "        img = self.tf(img).repeat(3, 1, 1)\n",
    "        label = torch.from_numpy(self.y[idx]).float()\n",
    "        return img, label\n",
    "\n",
    "# ─────────── 2) Self‐Supervised Transforms & DataModule ───────────\n",
    "\n",
    "class DinoTransform:\n",
    "    def __init__(self, img_size=224):\n",
    "        flip   = transforms.RandomHorizontalFlip()\n",
    "        color  = transforms.RandomApply(\n",
    "            [transforms.ColorJitter(0.4,0.4,0.2,0.1)], p=0.8\n",
    "        )\n",
    "        gray   = transforms.RandomGrayscale(p=0.2)\n",
    "        normalize = transforms.Normalize([0.5], [0.5])\n",
    "\n",
    "        self.global_t = transforms.Compose([\n",
    "            transforms.Resize(img_size, interpolation=InterpolationMode.BICUBIC),\n",
    "            flip, color, gray,\n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        g1 = self.global_t(x)\n",
    "        g2 = self.global_t(x)\n",
    "        return g1.repeat(3,1,1), g2.repeat(3,1,1)\n",
    "\n",
    "class ChestNpzSSL(Dataset):\n",
    "    def __init__(self, npz_path: Path):\n",
    "        self.arr = np.load(npz_path)[\"train_images\"]\n",
    "        self.tf  = DinoTransform()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.arr)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = (self.arr[idx] * 255).astype(\"uint8\")\n",
    "        img = Image.fromarray(img).convert(\"L\")\n",
    "        return self.tf(img)\n",
    "\n",
    "class ChestSSLDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, npz_path, batch=128, workers=0):\n",
    "        super().__init__()\n",
    "        self.path = Path(npz_path)\n",
    "        self.batch = batch\n",
    "        self.workers = workers\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.ds = ChestNpzSSL(self.path)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.ds,\n",
    "            batch_size=self.batch,\n",
    "            shuffle=True,\n",
    "            num_workers=self.workers,\n",
    "            pin_memory=False\n",
    "        )\n",
    "\n",
    "# ─────────── 3) Updated DINO Loss with Center Update ───────────\n",
    "\n",
    "class DinoLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Simplified DINO loss with center updating to prevent collapse.\n",
    "    \"\"\"\n",
    "    def __init__(self, out_dim=256, teacher_temp=0.04, student_temp=0.1, center_m=0.9):\n",
    "        super().__init__()\n",
    "        self.teacher_temp = teacher_temp\n",
    "        self.student_temp = student_temp\n",
    "        self.center_m = center_m\n",
    "        self.register_buffer(\"center\", torch.zeros(1, out_dim))\n",
    "\n",
    "    def forward(self, student_out, teacher_out):\n",
    "        # sharpen teacher with current center\n",
    "        t_out = F.softmax((teacher_out - self.center) / self.teacher_temp, dim=-1)\n",
    "        s_out = F.log_softmax(student_out / self.student_temp, dim=-1)\n",
    "        loss = -(t_out * s_out).sum(dim=-1).mean()\n",
    "\n",
    "        # EMA update of center\n",
    "        with torch.no_grad():\n",
    "            batch_center = t_out.mean(dim=0, keepdim=True)\n",
    "            self.center.mul_(self.center_m).add_(batch_center, alpha=1 - self.center_m)\n",
    "\n",
    "        return loss\n",
    "\n",
    "# ─────────── 4) Lightning Module ───────────\n",
    "\n",
    "class LitDINO(pl.LightningModule):\n",
    "    def __init__(self, lr=3e-4, out_dim=256, warmup_epochs=5, max_epochs=40):\n",
    "        super().__init__()\n",
    "        # student & teacher backbones\n",
    "        self.student = timm.create_model('vit_tiny_patch16_224', num_classes=0)\n",
    "        self.teacher = timm.create_model('vit_tiny_patch16_224', num_classes=0)\n",
    "\n",
    "        embed_dim = self.student.num_features  # 192\n",
    "        # projection heads\n",
    "        self.student_head = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_dim, out_dim),\n",
    "        )\n",
    "        self.teacher_head = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_dim, out_dim),\n",
    "        )\n",
    "\n",
    "        for p in self.teacher.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        self.criterion = DinoLoss(out_dim)\n",
    "        self.lr = lr\n",
    "        self.max_epochs = max_epochs\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        g1, g2 = batch\n",
    "        # student embeddings\n",
    "        feat1 = self.student(g1)  # [B, 192]\n",
    "        feat2 = self.student(g2)\n",
    "        s1 = self.student_head(feat1)\n",
    "        s2 = self.student_head(feat2)\n",
    "        # teacher embeddings\n",
    "        with torch.no_grad():\n",
    "            t_feat1 = self.teacher(g1)\n",
    "            t_feat2 = self.teacher(g2)\n",
    "            t1 = self.teacher_head(t_feat1)\n",
    "            t2 = self.teacher_head(t_feat2)\n",
    "        # compute DINO loss\n",
    "        loss = 0.5 * (self.criterion(s1, t2) + self.criterion(s2, t1))\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        # momentum update teacher\n",
    "        m = 0.996\n",
    "        with torch.no_grad():\n",
    "            for ps, pt in zip(self.student.parameters(), self.teacher.parameters()):\n",
    "                pt.data.mul_(m).add_(ps.data, alpha=1 - m)\n",
    "            for hs, ht in zip(self.student_head.parameters(), self.teacher_head.parameters()):\n",
    "                ht.data.mul_(m).add_(hs.data, alpha=1 - m)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.student.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.max_epochs)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "# ─────────── 5) Progress Callback & Training Entry ───────────\n",
    "\n",
    "class BatchProgressCallback(pl.callbacks.Callback):\n",
    "    def on_train_epoch_start(self, *_):\n",
    "        self.start = time.time()\n",
    "    def on_train_batch_end(self, trainer, *_):\n",
    "        if trainer.global_step % 50 == 0:\n",
    "            mb = torch.cuda.max_memory_allocated() / 1024**2 if torch.cuda.is_available() else 0\n",
    "            ex_s = (trainer.accumulate_grad_batches * trainer.train_dataloader.batch_size * 50) \\\n",
    "                   / max(1e-3, time.time() - self.start)\n",
    "            trainer.progress_bar_callback.progress.print(\n",
    "                f\"🖥️ GPU {mb:.0f} MB  ⚡ {ex_s:.1f} img/s\"\n",
    "            )\n",
    "            self.start = time.time()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import torch.multiprocessing as mp\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "    # DataModule\n",
    "    npz_path = r\"C:\\Users\\offic\\OneDrive\\Masaüstü\\datasets\\SelfSupervised\\chestmnist.npz\"\n",
    "    dm_ssl = ChestSSLDataModule(npz_path, batch=128, workers=0)\n",
    "\n",
    "    # Model\n",
    "    model_ssl = LitDINO(lr=3e-4, max_epochs=40)\n",
    "\n",
    "    # Callbacks\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(dirpath=\"checkpoints\", save_top_k=-1, every_n_epochs=5),\n",
    "        LearningRateMonitor(logging_interval='step'),\n",
    "        RichProgressBar(theme=RichProgressBarTheme(description=\"blue\", progress_bar=\"green\")),\n",
    "        BatchProgressCallback(),\n",
    "    ]\n",
    "\n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "        devices=1,\n",
    "        precision=\"16-mixed\",\n",
    "        max_epochs=40,\n",
    "        accumulate_grad_batches=2,\n",
    "        callbacks=callbacks,\n",
    "        log_every_n_steps=10,\n",
    "        enable_progress_bar=True,\n",
    "    )\n",
    "\n",
    "    # Start training\n",
    "    trainer.fit(model_ssl, datamodule=dm_ssl)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
